{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuchimishra/Model_deployment_using_Kubernetes_and_Docker/blob/main/Running_Flask_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-MlOTXR-hv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8832db37-b2f4-474e-b52c-413e3d1e998e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the model output and tokens from Google drive to current location"
      ],
      "metadata": {
        "id": "5Qtk6O1jUuc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/Data Science & Machine Learning/MLOps/Repository/model_output\" \"/content\""
      ],
      "metadata": {
        "id": "iDEkUGs2U9a5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/model_output\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R83irMgVmsU",
        "outputId": "77dc39b9-e07b-47ca-fc86-968c32ee421c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sa_encoder.vocab.tokens  sentiment_analysis.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGokItTB-jhh"
      },
      "source": [
        "# !ls '/content/drive/My Drive/Colab Notebooks/models/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import all libraries"
      ],
      "metadata": {
        "id": "54IxhCZxbn4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import socket\n"
      ],
      "metadata": {
        "id": "6EwBPFLzbugM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View Socket details"
      ],
      "metadata": {
        "id": "lFEDwjRhb_W7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk6pqXHXpChi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b0a19e-f2cd-4e72-d69b-300809ab6f59"
      },
      "source": [
        "print(socket.gethostname())\n",
        "print(socket.gethostbyname(socket.gethostname()))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "173deae104a1\n",
            "172.28.0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del app, model, text_encoder, padding_size, request"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "FihW9gpYlJIo",
        "outputId": "8877fef9-c11c-401e-cd1e-822f98fd97ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'app' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf65fefb0823>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'app' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, jsonify, make_response, request"
      ],
      "metadata": {
        "id": "IWbsh1JOrr2o"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize Flask app\n",
        "app = Flask(__name__)"
      ],
      "metadata": {
        "id": "ZyHIzRF5cPdO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import threading\n",
        "import json\n",
        "import requests"
      ],
      "metadata": {
        "id": "aCOv0C2erddr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padding_size = 1000\n",
        "\n",
        "\n",
        "# Load the model and tokens\n",
        "model = tf.keras.models.load_model('/content/model_output/sentiment_analysis.hdf5')\n",
        "text_encoder = tfds.deprecated.text.TokenTextEncoder.load_from_file(\"/content/model_output/sa_encoder.vocab\") #this feature is deprecated; for demo purpose only"
      ],
      "metadata": {
        "id": "HOn17s6DeKMW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DUmBgC4tLgD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0206361-5891-4ce3-cff4-10e1abe39875"
      },
      "source": [
        "@app.route('/')\n",
        "def hello():\n",
        "  return \"I am alive!\"\n",
        "\n",
        "def pad_to_size(vec, size):\n",
        "    zeros = [0] * (size - len(vec))\n",
        "    vec.extend(zeros)\n",
        "    return vec\n",
        "\n",
        "\n",
        "def predict_fn(predict_text, pad_size):\n",
        "    encoded_text = text_encoder.encode(predict_text)\n",
        "    encoded_text = pad_to_size(encoded_text, pad_size)\n",
        "    encoded_text = tf.cast(encoded_text, tf.int64)\n",
        "    predictions = model.predict(tf.expand_dims(encoded_text, 0))\n",
        "\n",
        "    return (predictions.tolist())\n",
        "\n",
        "\n",
        "@app.route('/seclassifier', methods=['POST'])\n",
        "def predict_sentiment():\n",
        "    text = request.get_json()['text']\n",
        "    print(text)\n",
        "    predictions = predict_fn(text, padding_size)\n",
        "    sentiment = 'positive' if float(''.join(map(str,predictions[0]))) > 0 else 'Negative'\n",
        "    return jsonify({'predictions ':predictions, 'sentiment ': sentiment})\n",
        "\n",
        "\n",
        "threading.Thread(target=app.run, kwargs={'host':'0.0.0.0','port':8000}).start()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model and Vocabalory loaded.......\n",
        " * Serving Flask app \"__main__\" (lazy loading)\n",
        " * Environment: production\n",
        "   WARNING: This is a development server. Do not use it in a production deployment.\n",
        "   Use a production WSGI server instead.\n",
        " * Debug mode: off\n",
        " * Running on http://0.0.0.0:6000/ (Press CTRL+C to quit)"
      ],
      "metadata": {
        "id": "2VXli_XyiPoR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDrmi6eQuHDQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1612dabb-63e3-47d7-99c9-38d3e95e8472"
      },
      "source": [
        "\n",
        "req = requests.get(\"http://172.28.0.12:8000\") #http://172.28.0.2:6000/\n",
        "print(req.status_code)\n",
        "print(req.text)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:8000\n",
            " * Running on http://172.28.0.12:8000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:172.28.0.12 - - [18/Jun/2024 00:11:17] \"GET / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "I am alive!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seclassifier = \"http://172.28.0.12:8000/seclassifier\""
      ],
      "metadata": {
        "id": "jJfXjbBZmb6w"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0Vbn3kFz3V2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9582968-3086-47e6-b9bc-e96463e9d55b"
      },
      "source": [
        "headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
        "data = {\"text\":\"Still working my way through it but definitely changes your view on investment. Wish it was available on Audible\"}\n",
        "req = requests.post(seclassifier,  data=json.dumps(data), headers=headers)\n",
        "\n",
        "print(req.status_code)\n",
        "print(req.text)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Still working my way through it but definitely changes your view on investment. Wish it was available on Audible\n",
            "1/1 [==============================] - 4s 4s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:172.28.0.12 - - [18/Jun/2024 00:11:20] \"POST /seclassifier HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "{\"predictions \":[[0.8370057344436646]],\"sentiment \":\"positive\"}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stWiQxHI16Qi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aab9563-fc5f-43e9-c700-87541920e997"
      },
      "source": [
        "app.app_context().push()\n",
        "headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
        "data = {\"text\":\"I thought this will be good one. But I was wrong\"}\n",
        "req = requests.post(seclassifier,  data=json.dumps(data), headers=headers)\n",
        "\n",
        "print(req.status_code)\n",
        "print(req.text)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I thought this will be good one. But I was wrong\n",
            "1/1 [==============================] - 1s 634ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:172.28.0.12 - - [18/Jun/2024 00:11:21] \"POST /seclassifier HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "{\"predictions \":[[-0.8676939606666565]],\"sentiment \":\"Negative\"}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0jA9Xev2zz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "192f6e32-8a26-4843-a027-101786a76ecc"
      },
      "source": [
        "!ps -eaf | grep python"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root          61       6  0 Jun17 ?        00:00:07 [python3] <defunct>\n",
            "root          62       6  0 Jun17 ?        00:00:00 python3 /usr/local/bin/colab-fileshim.py\n",
            "root          82       6  0 Jun17 ?        00:00:06 /usr/bin/python3 /usr/local/bin/jupyter-notebook\n",
            "root         596     592  0 Jun17 ?        00:00:00 python3 /opt/google/drive/drive-filter.py\n",
            "root        9142      82 21 00:10 ?        00:00:15 /usr/bin/python3 -m colab_kernel_launcher -f /ro\n",
            "root        9163       1  0 00:10 ?        00:00:00 /usr/bin/python3 /usr/local/lib/python3.10/dist-\n",
            "root        9526    9142  0 00:11 ?        00:00:00 /bin/bash -c ps -eaf | grep python\n",
            "root        9528    9526  0 00:11 ?        00:00:00 grep python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGJiHeCD5a1K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "821b07ec-2cf4-4acc-f9bf-417ab2875e71"
      },
      "source": [
        "import flask\n",
        "flask.__version__"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDJ3bhrzG65X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "224ca0e3-976b-4407-d0df-f183b515adca"
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.10/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.31.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok==4.1.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez8XDSpwuIVv",
        "outputId": "fc24bf11-31c7-480b-fdcb-22116cc70bb8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok==4.1.1\n",
            "  Downloading pyngrok-4.1.1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyngrok==4.1.1) (0.18.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok==4.1.1) (6.0.1)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-4.1.1-py3-none-any.whl size=15964 sha256=7fbcf24859c963d5406a76a35fd755bd27f5558bafa052c16667d5b5dc254f9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/7c/4c/632fba2ea8e88d8890102eb07bc922e1ca8fa14db5902c91a8\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-4.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35JGfAl1yXvE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f295ddf-218e-415f-83af-1d6951cc3c31"
      },
      "source": [
        "ngrok_token = \"\" # @param {type:\"string\"}\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from flask import Flask, jsonify, make_response, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "!ngrok config add-authtoken ngrok_token #Important code\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "padding_size = 1000\n",
        "model = tf.keras.models.load_model('/content/model_output/sentiment_analysis.hdf5')\n",
        "text_encoder = tfds.deprecated.text.TokenTextEncoder.load_from_file(\"/content/model_output/sa_encoder.vocab\")\n",
        "\n",
        "print('Model and Vocabalory loaded.......')\n",
        "\n",
        "@app.route(\"/\")\n",
        "def hello():\n",
        "    return \"I am alive!\"\n",
        "\n",
        "def pad_to_size(vec, size):\n",
        "    zeros = [0] * (size - len(vec))\n",
        "    vec.extend(zeros)\n",
        "    return vec\n",
        "\n",
        "\n",
        "def predict_fn(predict_text, pad_size):\n",
        "    encoded_text = text_encoder.encode(predict_text)\n",
        "    encoded_text = pad_to_size(encoded_text, pad_size)\n",
        "    encoded_text = tf.cast(encoded_text, tf.int64)\n",
        "    predictions = model.predict(tf.expand_dims(encoded_text, 0))\n",
        "\n",
        "    return (predictions.tolist())\n",
        "\n",
        "\n",
        "@app.route('/seclassifier', methods=['POST'])\n",
        "def predict_sentiment():\n",
        "    text = request.get_json()['text']\n",
        "    print(text)\n",
        "    predictions = predict_fn(text, padding_size)\n",
        "    sentiment = 'positive' if float(''.join(map(str,predictions[0]))) > 0 else 'Negative'\n",
        "    return jsonify({'predictions ':predictions, 'sentiment ': sentiment})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME:\n",
            "   ngrok - tunnel local ports to public URLs and inspect traffic\n",
            "\n",
            "DESCRIPTION:\n",
            "    ngrok exposes local networked services behinds NATs and firewalls to the\n",
            "    public internet over a secure tunnel. Share local websites, build/test\n",
            "    webhook consumers and self-host personal services.\n",
            "    Detailed help for each command is available with 'ngrok help <command>'.\n",
            "    Open http://localhost:4040 for ngrok's web interface to inspect traffic.\n",
            "\n",
            "EXAMPLES:\n",
            "    ngrok http 80                    # secure public URL for port 80 web server\n",
            "    ngrok http -subdomain=baz 8080   # port 8080 available at baz.ngrok.io\n",
            "    ngrok http foo.dev:80            # tunnel to host:port instead of localhost\n",
            "    ngrok http https://localhost     # expose a local https server\n",
            "    ngrok tcp 22                     # tunnel arbitrary TCP traffic to port 22\n",
            "    ngrok tls -hostname=foo.com 443  # TLS traffic for foo.com to port 443\n",
            "    ngrok start foo bar baz          # start tunnels from the configuration file\n",
            "\n",
            "VERSION:\n",
            "   2.3.41\n",
            "\n",
            "AUTHOR:\n",
            "  inconshreveable - <alan@ngrok.com>\n",
            "\n",
            "COMMANDS:\n",
            "   authtoken\tsave authtoken to configuration file\n",
            "   credits\tprints author and licensing information\n",
            "   http\t\tstart an HTTP tunnel\n",
            "   start\tstart tunnels by name from the configuration file\n",
            "   tcp\t\tstart a TCP tunnel\n",
            "   tls\t\tstart a TLS tunnel\n",
            "   update\tupdate ngrok to the latest version\n",
            "   version\tprint the version string\n",
            "   help\t\tShows a list of commands or help for one command\n",
            "\n",
            "ERROR:  Unrecognized command: config\n",
            "Model and Vocabalory loaded.......\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "Exception in thread Thread-18:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 203, in _new_conn\n",
            "    sock = connection.create_connection(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 791, in urlopen\n",
            "    response = self._make_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 497, in _make_request\n",
            "    conn.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 395, in request\n",
            "    self.endheaders()\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 243, in connect\n",
            "    self.sock = self._new_conn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 218, in _new_conn\n",
            "    raise NewConnectionError(\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7c3fcc36c730>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 486, in send\n",
            "    resp = conn.urlopen(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 845, in urlopen\n",
            "    retries = retries.increment(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\", line 515, in increment\n",
            "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7c3fcc36c730>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1378, in run\n",
            "    self.function(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask_ngrok.py\", line 70, in start_ngrok\n",
            "    ngrok_address = _run_ngrok()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flask_ngrok.py\", line 35, in _run_ngrok\n",
            "    tunnel_url = requests.get(localhost_url).text  # Get the tunnel information\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 73, in get\n",
            "    return request(\"get\", url, params=params, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 59, in request\n",
            "    return session.request(method=method, url=url, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 589, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 703, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 519, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7c3fcc36c730>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the model output and tokens from Google drive to current location"
      ],
      "metadata": {
        "id": "Wm1Fyx1_uumg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/Data Science & Machine Learning/MLOps/Repository/model_output\" \"/content\""
      ],
      "metadata": {
        "id": "d3_oWcS4uums"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/model_output\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9f52981-cde8-47c9-f823-234622c86538",
        "id": "abVDiCDruumt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sa_encoder.vocab.tokens  sentiment_analysis.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vgwRobA02md"
      },
      "source": [],
      "execution_count": 24,
      "outputs": []
    }
  ]
}